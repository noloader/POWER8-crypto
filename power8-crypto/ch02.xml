<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="ch02">
  <title>Vector programming</title>
  <para>Several topics need to be discussed to minimize trouble when using the Altivec and POWER8 extensions. They include PowerPC compilers and options, Altivec headers, machine endianness, vector datatypes, memory and alignment, and loads and stores. It is enough information to get to the point you can use AES and SHA but not much more.</para>
  <para>Memory alignment, loads, stores and shifts will probably cause the most trouble for someone new to PowerPC vector programming. If you are new to the platform you may want to read this chapter twice. If you are experienced with the platform then you probably want to skip this chapter.</para>
  <para>Two compilers are used for testing. The first is GCC and the second is IBM XL C/C++ (XLC). Both produce high quality code. The GCC and XLC compilers are mostly the same but accept slightly different options. LLVM's Clang was not tested because the <link linkend="intro_cfarm">compile farm </link> lacks a Clang installation.</para>
  <section id="gcc_compiler" xreflabel="GCC Compiler">
    <title>GCC compiler</title>
    <para>Compiling a test program with GCC will generally look like below. The important part is <systemitem>-mcpu=power8</systemitem> which selects the POWER8 Instruction Set Architecture (ISA). The minimum architecture required for Altivec with GCC is <systemitem>-march=power4</systemitem>.</para>
    <programlisting>$ g++ -mcpu=power8 -maltivec test.cxx -o test.exe</programlisting>
    <para>GCC consumes <systemitem>-g</systemitem> and <systemitem>-O3</systemitem>. If you want Position Independent Code then use <systemitem>-fPIC</systemitem>.</para>
    <para>GCC uses integer math to calculate the effective memory addresses from a memory address and offset. That is, if you have an array <systemitem>uint32_t vals = {0,1,2,3,4,5,6,7}</systemitem>, and you call <systemitem>uint32x4_p v = vec_xl(vals, 4)</systemitem>, then the vector will have the value <systemitem>{1,2,3,4}</systemitem>. That is, GCC uses the address of <systemitem>vals</systemitem> and simply adds <systemitem>4</systemitem> to it. Effective addresses are discussed in <xref linkend="effective_address"/>, and loads and stores are discussed in <xref linkend="altivec_aligned_ld_st"/>.</para>
    <para>If you work on the <link linkend="intro_cfarm">Compile Farm</link> then be mindful of the default GCC compiler. It may be GCC 4.8.5 which is a bit old and unsupported. You usually enjoy better code generation and performance with a modern GCC like 7.2. A newer compiler is usually located at <systemitem>/opt/cfarm/gcc-latest</systemitem>.</para>
  </section>
  <section id="xlc_compiler" xreflabel="XLC Compiler">
    <title>XLC compiler</title>
    <para>Compiling a test program with IBM XL C/C++ will generally look like below. The important parts are the C++ compiler name of <systemitem>xlC</systemitem>, and <systemitem>-qarch=pwr8</systemitem> which selects the POWER8 ISA. The minimum architecture required for Altivec with XLC is <systemitem>-qarch=pwr6</systemitem>.</para>
    <programlisting>$ xlC -qarch=pwr8 -qaltivec test.cxx -o test.exe</programlisting>
    <para>XLC consumes <systemitem>-g</systemitem> and <systemitem>-O3</systemitem>. If you want Position Independent Code then use <systemitem>-qpic</systemitem> for XLC.</para>
    <para>XLC uses integer math to calculate the effective memory addresses from a memory address and offset. That is, if you have an array <systemitem>uint32_t vals = {0,1,2,3,4,5,6,7}</systemitem>, and you call <systemitem>uint32x4_p v = vec_xl(vals, 4)</systemitem>, then the vector will have the value <systemitem>{1,2,3,4}</systemitem>. That is, XLC uses the address of <systemitem>vals</systemitem> and simply adds <systemitem>4</systemitem> to it. Effective addresses are discussed in <xref linkend="effective_address"/>, and loads and stores are discussed in <xref linkend="altivec_aligned_ld_st"/>.</para>
    <para>IBM XLC switched to a LLVM front-end for the Linux compiler at version 13.1 (AIX still uses the IBM front-end). When compiling with XLC version 13.1 or higher on Linux you may need the <systemitem>-qcompatmacros</systemitem> compiler option. Without <systemitem>-qcompatmacros</systemitem> the samples fail to compile because XLC 13.1 does not define <systemitem>__xlc__</systemitem> or <systemitem>__xlC__</systemitem>. However, LLVM defines <systemitem>__GNUC__</systemitem> but compilation fails because the compiler cannot consume the GCC POWER8 builtins.<footnote><para>LLVM behavior is befuddling to some people. It is the XLC compiler but fails to define <systemitem>__xlc__</systemitem> or <systemitem>__xlC__</systemitem>. Then it defines <systemitem>__GNUC__</systemitem> but fails to consume the GCC POWER8 builtins.</para></footnote></para>
  </section>
  <section id="clang_compiler" xreflabel="Clang Compiler">
    <title>Clang compiler</title>
    <para>There are two LLVM components you should be aware of. First is the LLVM Clang compiler. The second is the LLVM front-end used by XLC 13.1 and above on Linux. The Clang compiler is what you normally think of. The compiler has its own set of builtins to use for crypto programming on POWER8. The Clang compiler was not tested because the <link linkend="intro_cfarm">compile farm </link> lacks a Clang installation.</para>
    <para>Clang uses pointer math to calculate the effective memory addresses from a memory address and offset. That is, if you have an array <systemitem>uint32_t vals = {0,1,2,3,4,5,6,7}</systemitem>, and you call <systemitem>uint32x4_p v = vec_xl(vals, 4)</systemitem>, then the vector will have the value <systemitem>{4,5,6,7}</systemitem>. That is, Clang uses the address of <systemitem>vals</systemitem> and adds <systemitem>4*sizeof(uint32_t)</systemitem> to it. Effective addresses are discussed in <xref linkend="effective_address"/>, and loads and stores are discussed in <xref linkend="altivec_aligned_ld_st"/>.</para>
    <para>If you use the Clang compiler then be sure it is version 7.1 or above due to <ulink url="https://bugs.llvm.org/show_bug.cgi?id=39704">Bug 39704</ulink>. The 39704 bug is due to Clang discarding code it believed was illegal due to an unaligned Altivec load. The code was legal because POWER7 and VSX provides the load of data using natural alignment. The code should not have been removed.</para>
  </section>
  <section id="altivec_header" xreflabel="Altivec Headers">
    <title>Altivec headers</title>
    <para>The header file required for datatypes and functions is <systemitem>&lt;altivec.h&gt;</systemitem>. You must enable Altivec using compiler options <systemitem>-maltivec</systemitem> or <systemitem>-qaltivec</systemitem> as discussed in <xref linkend="gcc_compiler"/> and <xref linkend="xlc_compiler"/>.</para>
    <para>To support C++ projects and compilers the <systemitem>__vector</systemitem> keyword is used rather than <systemitem>vector</systemitem>. A typical Altivec include looks as shown below.</para>
    <programlisting>#if defined(__ALTIVEC__)
# include &lt;altivec.h&gt;
# include &lt;altivec.h&gt;
# undef vector
# undef pixel
# undef bool
#endif</programlisting>
    <para>The <systemitem>__ALTIVEC__</systemitem> preprocessor macro will be defined when using <systemitem>-qaltivec</systemitem> or <systemitem>-maltivec</systemitem> compiler options as discussed in <xref linkend="gcc_compiler"/> and <xref linkend="xlc_compiler"/>. Macros and definitions are discussed more in <xref linkend="preprocessor_macros"/>.</para>
    <para>When you need to use the vector datatypes you use the <systemitem>__vector</systemitem> keyword as discussed in the section <xref linkend="power8_datatypes"/>.</para>
    <programlisting>/* A vector with four elements initialized to 0 */
__vector unsigned int v = {0,0,0,0};</programlisting>
  </section>
  <section id="preprocessor_macros" xreflabel="Preprocessor Macros">
    <title>Preprocessor macros</title>
    <para>The following preprocessor macros and defines will be encountered depending on the platform and compiler:</para>
    <itemizedlist mark="bullet">
      <listitem>
        <para><systemitem>__powerpc__</systemitem> and <systemitem>__powerpc</systemitem> on AIX
        </para>
      </listitem>
      <listitem>
        <para><systemitem>__powerpc__</systemitem> and <systemitem>__powerpc64__</systemitem> on Linux
        </para>
      </listitem>
      <listitem>
        <para><systemitem>_ARCH_PWR3</systemitem> through <systemitem>_ARCH_PWR9</systemitem> on AIX and Linux
        </para>
      </listitem>
      <listitem>
        <para><systemitem>__linux__</systemitem>, <systemitem>__linux</systemitem> and <systemitem>linux</systemitem> on Linux
        </para>
      </listitem>
      <listitem>
        <para><systemitem>_AIX</systemitem>, and <systemitem>_AIX32</systemitem> through <systemitem>_AIX72</systemitem> on AIX
        </para>
      </listitem>
      <listitem>
        <para><systemitem>__GNUC__</systemitem> when using GCC C/C++ compiler
        </para>
      </listitem>
      <listitem>
        <para><systemitem>__xlc__</systemitem> and <systemitem>__xlC__</systemitem> when using IBM XL C/C++
        </para>
      </listitem>
    </itemizedlist>
    <para><indexterm><primary>LLVM</primary></indexterm><indexterm><primary>Clang</primary></indexterm>IBM switched to an LLVM front-end for the Linux compiler at version 13.1 as discussed in <xref linkend="xlc_compiler"/>. Be mindful of how you use preprocessor macros when LLVM is the front-end because the compiler claims to be three different compilers (GCC, Clang and XLC).</para>
    <programlisting>$ xlc -qxlcompatmacros -qshowmacros -E test.cxx | \
  egrep -i -E 'xlc|clang|llvm|gnuc'
#define __GNUC_GNU_INLINE__ 1
#define __GNUC_MINOR__ 2
#define __GNUC_PATCHLEVEL__ 1
#define __GNUC__ 4
#define __clang__ 1
#define __clang_major__ 4
#define __clang_minor__ 0
#define __clang_patchlevel__ 1
#define __llvm__ 1
#define __xlC__ 0x0d01
#define __xlC_ver__ 0x00000601</programlisting>
    <para>The front-end change triggered <ulink url="http://bugs.llvm.org/show_bug.cgi?id=38378">LLVM Issue 38378</ulink> for one project because the compiler entered GCC code paths but it cannot consume GCC POWER8 builtins.</para>
  </section>
  <section id="power8_endianess" xreflabel="Machine Endianness">
    <title>Machine endianness</title>
    <para>You will experience both little-endian and big-endian machines in the field when working with a modern PowerPC architecture. Linux is generally little-endian, while AIX is big-endian.</para>
    <para>When writing portable source code you should check the value of preprocessor macros <systemitem>__LITTLE_ENDIAN__</systemitem> or <systemitem>__BIG_ENDIAN__</systemitem> to determine the configuration. The value of the macros <systemitem>__BIG_ENDIAN__</systemitem> and <systemitem>__LITTLE_ENDIAN__</systemitem> are defined to non-0 when in effect. Source code checking endianness should look similar to the code shown below.</para>
    <programlisting>#if __LITTLE_ENDIAN__
# pragma message "Little-endian system"
#else
# pragma message "Big-endian system"
#endif</programlisting>
    <para>The compilers can show the endian-related preprocessor macros available on a platform. Below is from GCC on <systemitem>gcc112</systemitem> from the <link linkend="intro_cfarm">compile farm</link>, which is ppc64-le.</para>
    <screen>$ g++ -dM -E test.cxx | grep -i endian
#define __ORDER_LITTLE_ENDIAN__ 1234
#define _LITTLE_ENDIAN 1
#define __FLOAT_WORD_ORDER__ __ORDER_LITTLE_ENDIAN__
#define __ORDER_PDP_ENDIAN__ 3412
#define __LITTLE_ENDIAN__ 1
#define __ORDER_BIG_ENDIAN__ 4321
#define __BYTE_ORDER__ __ORDER_LITTLE_ENDIAN__
</screen>
    <para>And the complimentary view from IBM XL C/C++ on <systemitem>gcc112</systemitem> from the <xref linkend="intro_cfarm"/>, which is ppc64-le.</para>
    <screen>$ xlC -qshowmacros -E test.cxx | grep -i endian
#define _LITTLE_ENDIAN 1
#define __BYTE_ORDER__ __ORDER_LITTLE_ENDIAN__
#define __FLOAT_WORD_ORDER__ __ORDER_LITTLE_ENDIAN__
#define __LITTLE_ENDIAN__ 1
#define __ORDER_BIG_ENDIAN__ 4321
#define __ORDER_LITTLE_ENDIAN__ 1234
#define __ORDER_PDP_ENDIAN__ 3412
#define __VEC_ELEMENT_REG_ORDER__ __ORDER_LITTLE_ENDIAN__
</screen>
    <para>However, below is <systemitem>gcc119</systemitem> from the <link linkend="intro_cfarm">compile farm</link>, which is ppc64-be. It runs AIX and notice <systemitem>__BYTE_ORDER__</systemitem>, <systemitem>__ORDER_BIG_ENDIAN__</systemitem> and <systemitem>__ORDER_LITTLE_ENDIAN__</systemitem> are not present.</para>
    <screen>$ xlC -qshowmacros -E test.cxx | grep -i endian
#define __BIG_ENDIAN__ 1
#define _BIG_ENDIAN 1
#define __THW_BIG_ENDIAN__ 1
#define __HHW_BIG_ENDIAN__ 1
</screen>
    <para>PowerPC is not the only architecture to have the <systemitem>__BIG_ENDIAN__</systemitem> and <systemitem>__LITTLE_ENDIAN__</systemitem> trap. The trap is also laid on SPARCv8, and caused BIND users on NetBSD-8 to fail to validate DNSSEC keys. The problem was the endianess tests used <systemitem>__ORDER_BIG_ENDIAN__</systemitem> and <systemitem>__ORDER_LITTLE_ENDIAN__</systemitem>. Also see <ulink url="https://mail-index.netbsd.org/netbsd-users/2020/04/16/msg024529.html">DNSSEC vs netbsd-8/sparc?</ulink>.</para>
  </section>
  <section id="power8_alloc" xreflabel="Memory Allocation">
    <title>Memory allocation</title>
    <para>System calls like <systemitem>malloc</systemitem> and <systemitem>calloc</systemitem> (and friends) are used to acquire memory from the heap. The system calls <emphasis>do not</emphasis> guarantee alignment to any particular boundary on all platforms. Linux generally returns a pointer that is at least 16-byte aligned on all platforms, including ARM, PPC, MIPS and x86. AIX <emphasis>does not</emphasis> provide the same <ulink url="http://stackoverflow.com/q/48373188/608639">alignment behavior</ulink>.</para>
    <para>To avoid unexpected surprises when using heap allocations you should use <ulink url="http://pubs.opengroup.org/onlinepubs/009695399/functions/posix_memalign.html"><systemitem>posix_memalign</systemitem></ulink> to acquire heap memory aligned to a particular boundary and <systemitem>free</systemitem> to return it to the system.</para>
    <para>AIX provides routines for vector memory allocation and alignment. They are <systemitem>vec_malloc</systemitem> and <systemitem>vec_free</systemitem>, and you can use them like <systemitem>_mm_malloc</systemitem> on Intel machines with Streaming SIMD Extensions (SSE).</para>
  </section>
  <section id="power8_datatypes" xreflabel="Vector Datatypes">
    <title>Vector datatypes</title>
    <para>Three vector datatypes are needed for in-core programming. The three types used for crypto are listed below.</para>
    <itemizedlist mark="bullet">
      <listitem>
        <para>
          <systemitem>__vector unsigned char</systemitem>
        </para>
      </listitem>
      <listitem>
        <para>
          <systemitem>__vector unsigned int</systemitem>
        </para>
      </listitem>
      <listitem>
        <para>
          <systemitem>__vector unsigned long</systemitem>
        </para>
      </listitem>
    </itemizedlist>
    <para><systemitem>__vector unsigned char</systemitem> is arranged as 16 each 8-bit bytes, and it is a typedef to <systemitem>uint8x16_p</systemitem>. <systemitem>__vector unsigned int</systemitem> is arranged as 4 each 32-bit words, and it is a typedef to <systemitem>uint32x4_p</systemitem>.</para>
    <para>POWER7 and VSX added <systemitem>__vector unsigned long</systemitem>, and it is arranged as 2 each 64-bit double words. The typedef is <systemitem>uint64x2_p</systemitem>. According to the Power Architecture ELF ABI Specification, you should always use <systemitem>__vector unsigned long</systemitem> for portability because it is available on 32-bit and 64-bit systems. You should not use <systemitem>__vector unsigned long long</systemitem>.</para>
    <para>Though POWER7 and VSX added <systemitem>__vector unsigned long</systemitem>, the associated  64-bit vector operations did not arrive until POWER8. That means you can load a <systemitem>__vector unsigned long</systemitem>, but you can't add, subtract, or, or xor them until POWER8. You will be OK with crypto operations since crypto is POWER8.</para>
    <para>The typedef naming was selected to convey the arrangement, like <systemitem>32x4</systemitem> and <systemitem>64x2</systemitem>. The trailing <systemitem>_p</systemitem> was selected to convey the POWER architecture and avoid collisions with ARM NEON vector data types. The suffix <systemitem>_p8</systemitem> (for POWER8 architecture) or <systemitem>_v</systemitem> (for Vector) would work just as well. You should avoid <systemitem>_t</systemitem> because it is reserved for the language by the standards.</para>
  </section>
  <section id="power8_shift" xreflabel="Vector Shifts">
    <title>Vector shifts</title>
    <para>Altivec shifts and rotates are performed using <emphasis>Vector Shift Left Double by Octet Immediate</emphasis>. The vector shift and rotate builtin is <indexterm><primary>vec_sld</primary></indexterm><systemitem>vec_sld</systemitem> and it compiles/assembles to <indexterm><primary>vsldoi</primary></indexterm><systemitem>vsldoi</systemitem>. Both shift and rotate operate on a concatenation of two vectors. Bytes are shifted out on the left and shifted in on the right. The instructions need an integral constant in the range 0 - 15, inclusive.</para>
    <para>Vector shifts and rotates perform as expected on big-endian machines. Little-endian machines require special handling to produce correct results. The catch is, <ulink url="http://www.ibm.com/support/knowledgecenter/SSXVZZ_13.1.4/com.ibm.xlcpp1314.lelinux.doc/compiler_ref/vec_sld.html">IBM manuals don't tell you about it</ulink>.</para>
    <para>The issue is <ulink url="http://stackoverflow.com/q/46341923/608639">shifts and rotates are endian sensitive</ulink> and you have to use <systemitem>16-n</systemitem> integrals and swap vector arguments on little-endian systems. The C++ source code provides the following template function to compensate for the little-endian behavior.</para>
    <programlisting><indexterm><primary>VecShiftLeft</primary></indexterm><indexterm><primary>vec_sld</primary></indexterm>template &lt;unsigned int N, class T&gt;
T VecShiftLeft(const T val1, const T val2)
{
#if __LITTLE_ENDIAN__
    enum {R = (16-N)&amp;0xf};
    return vec_sld(val2, val1, R);
#else
    enum {R = N&amp;0xf};
    return vec_sld(val1, val2, R);
#endif
}</programlisting>
    <para>A <indexterm><primary>VecRotateLeft</primary></indexterm><systemitem>VecRotateLeft</systemitem> would be similar to the code below, if needed. Rotate is a special case of shift where both vector arguments are the same value.</para>
    <programlisting><indexterm><primary>VecRotateLeft</primary></indexterm><indexterm><primary>vec_sld</primary></indexterm>template &lt;unsigned int N, class T&gt;
T VecRotateLeft(const T val)
{
#if __LITTLE_ENDIAN__
    enum {R = (16-N)&amp;0xf};
    return vec_sld(val, val, R);
#else
    enum {R = N&amp;0xf};
    return vec_sld(val, val, R);
#endif
}</programlisting>
  </section>
  <section id="power8_permute" xreflabel="Vector Permutes">
    <title>Vector permutes</title>
    <para>Vector permutes allow you to rearrange elements in a vector. The values to be permuted can be in any arrangement like 64x2 or 32x4, but the mask is always an octet mask using an 8x16 arrangement.</para>
    <para>The Altivec permute is very powerful and it stands out among architectures like ARM, Aarch64 and x86. The instruction allows you to select elements from two source vectors. When an index in the mask is in the range <systemitem>[0,15]</systemitem> then elements from the first vector are selected, and index values in the the range <systemitem>[16,31]</systemitem> select elements from the second vector.</para>
    <para>As an example, suppose you have a big-endian byte array like a message to be hashed using SHA-256. SHA operates on 32-bit words so the message needs a shuffle on little-endian systems. The code to perform the permute on a little-endian machine would look like below.</para>
    <programlisting><indexterm><primary>vec_perm</primary></indexterm>uint32x4_p msg = vec_ld(/*load from memory*/);
uint8x16_p mask = {3,2,1,0, 7,6,5,4, 11,10,9,8, 15,14,13,12};
msg = vec_perm(msg, msg, mask);</programlisting>
    <para>The previous example only needed one vector so it used <systemitem>msg</systemitem> twice in the call to <systemitem>vec_perm</systemitem>. The Altivec code is similar to <systemitem>_mm_shuffle_epi8</systemitem> on Intel machines. An example that interleaves two different vectors is shown below.</para>
    <programlisting><indexterm><primary>vec_perm</primary></indexterm>uint32x4_p a = { 0,  0,  0,  0};  // All 0 bits
uint32x4_p b = {-1, -1, -1, -1};  // All 1 bits
uint8x16_p m = {0,1,2,3, 16,17,18,19, 4,5,6,7, 20,21,22,23};
uint32x4_p c = vec_perm(a, b, m);</programlisting>
    <para>After the code above executes the vector <systemitem>c</systemitem> will have the value <systemitem>{0, -1, 0, -1}</systemitem>.</para>
    <para>Below is the image IBM provides for the <systemitem>vec_perm</systemitem> documentation. The IBM example shows <systemitem>d = vec_perm(a, b, c)</systemitem>. The light gray blocks in vector <systemitem>d</systemitem> are from the first vector, and dark gray blocks in vector <systemitem>d</systemitem> are from the second vector.</para>
    <para/>
    <mediaobject>
      <imageobject>
        <imagedata fileref="images/vecperm.gif" width="5.25in" scalefit="1" format="GIF"/>
      </imageobject>
      <textobject>
        <phrase>Permute 16 8-bit integer elements.</phrase>
      </textobject>
    </mediaobject>
  </section>
  <section id="effective_address" xreflabel="Effective Addresses">
    <title>Effective addresses</title>
    <para>Some vector operations, like loads and stores, can be sensitive to the alignment of a memory address. Operations like <systemitem>vec_ld</systemitem> and <systemitem>vec_st</systemitem> are sensitive, and the documentation clearly states it.</para>
    <para>The effective address is a simple sum consisting of the memory address plus the offset into the address with the result rounded down to a multiple of 16. Effective addresses follow integer arithmetic and not pointer arithmetic.</para>
    <para>You can calculate an effective address using the following code. Notice the bottom 4 bits are masked after calculating the sum to yield a multiple of 16.</para>
    <programlisting>uintptr_t maddr = (uintptr_t)mem_addr;
uintptr_t mask = ~(uintptr_t)0xf;
uintptr_t eaddr = (maddr+offset) &amp; mask;</programlisting>
    <para><systemitem>vec_ld</systemitem> takes a pointer and an offset to load a value into a VSX register. Each of the following yield the same VSX register value because the effective addresses are the same. (Old x86 programmers should reminisce on  segmented memory).</para>
    <programlisting><indexterm><primary>vec_ld</primary></indexterm>uint8_t* ptr1 = 0x401000;
int off1 = 32;
uint8x16_p r1 = vec_ld(off1, ptr1);

uint8_t* ptr2 = 0x401010;
int off2 = 16;
uint8x16_p r2 = vec_ld(off2, ptr2);</programlisting>
    <para>The following also yields the same VSX register value because the effective address is the same. If you truly wanted to load 4 bytes beyond <systemitem>ptr</systemitem> then you loaded the wrong value because <systemitem>(0x401010+4)&amp;0xfffffff0 = 0x401010</systemitem>.</para>
    <programlisting><indexterm><primary>vec_ld</primary></indexterm>uint8_t* ptr1 = 0x401000;
int off1 = 16;
uint8x16_p r1 = vec_ld(off1, ptr1);

uint8_t* ptr2 = 0x401010;
int off2 = 4;
uint8x16_p r2 = vec_ld(off2, ptr2);</programlisting>
    <para>The application of effective addresses are discussed more below in <xref linkend="altivec_aligned_ld_st"/> and <xref linkend="vsx_unaligned_ld_st"/>.</para>
  </section>
  <section id="altivec_aligned_ld_st" xreflabel="Aligned Data References">
    <title>Aligned data references</title>
    <para>Altivec loads and stores have traditionally been performed using <systemitem>vec_ld</systemitem> and <systemitem>vec_st</systemitem> since at least the POWER4 days in the early 2000s. <systemitem>vec_ld</systemitem> and <systemitem>vec_st</systemitem> are sensitive to alignment of the effective address. Effective addresses were discussed in <xref linkend="effective_address"/>.</para>
    <para>Altivec <emphasis>does not</emphasis> raise a <systemitem>SIGBUS</systemitem> to indicate a misaligned load or store. Instead, the bottom 4 bits of the sum <systemitem>address+offset</systemitem> are masked-off and then the memory at the effective address is loaded.</para>
    <para>You can use the Altivec loads and stores when you <emphasis>control</emphasis> buffers and ensure they are 16-byte aligned, like an AES key schedule table. Otherwise just use <link linkend="vsx_unaligned_ld_st">unaligned loads and stores</link> to avoid trouble.</para>
    <para>The C/C++ code to perform a load using <indexterm><primary>vec_ld</primary></indexterm><systemitem>vec_ld</systemitem> should look similar to below. Notice the <systemitem>assert</systemitem> to warn you of problems in debug builds.</para>
    <programlisting><indexterm><primary>VecLoad</primary></indexterm><indexterm><primary>vec_ld</primary></indexterm>template &lt;class T&gt;
uint32x4_p VecLoad(const T* mem_addr, int offset)
{
#ifndef NDEBUG
    uintptr_t maddr = (uintptr_t)mem_addr;
    uintptr_t mask = ~(uintptr_t)0xf;
    uintptr_t eaddr = (maddr+offset) &amp; mask;
    assert(maddr == eaddr);
#endif

    return (uint32x4_p)vec_ld(offset, mem_addr);
}</programlisting>
    <para>The C/C++ code to perform a store using <indexterm><primary>vec_st</primary></indexterm><systemitem>vec_st</systemitem> should look similar to below.</para>
    <programlisting><indexterm><primary>VecStore</primary></indexterm><indexterm><primary>vec_st</primary></indexterm>template &lt;class T&gt;
void VecStore(const uint32x4_p val, T* mem_addr, int offset)
{
#ifndef NDEBUG
    uintptr_t maddr = (uintptr_t)mem_addr;
    uintptr_t mask = ~(uintptr_t)0xf;
    uintptr_t eaddr = (maddr+offset) &amp; mask;
    assert(maddr == eaddr);
#endif

    vec_st((uint8x16_p)val, offset, mem_addr);
}</programlisting>
  </section>
  <section id="vsx_unaligned_ld_st" xreflabel="Unaligned Data References">
    <title>Unaligned data references</title>
    <para>POWER7 and VSX introduced unaligned loads and stores for 32-bit and 64-bit datatypes that avoid the 16-byte aligned memory requirements of Altivec. POWER9 introduced unaligned loads and stores for 8-bit and 16-bit datatypes. While POWER9 allows you to load a byte array, POWER7 and POWER8 limits you to 32-bit and 64-bit arrays. If you have a byte array on POWER7, then it must be at least 32-bit aligned or you have to use the Altivec load.</para>
    <para>The preferred builtin functions for 32-bit and 64-bit unaligned loads and stores are <indexterm><primary>vec_xl</primary></indexterm><systemitem>vec_xl</systemitem> and <indexterm><primary>vec_xst</primary></indexterm><systemitem>vec_xst</systemitem>. The builtins are available on all currently supported versions of GCC and XLC. However, older versions of GCC such as those installed on many enterprise Linux distributions do not supply them. For compatibility with these older compilers you may use <indexterm><primary>vec_vsx_ld</primary></indexterm><systemitem>vec_vsx_ld</systemitem> and <indexterm><primary>vec_vsx_st</primary></indexterm><systemitem>vec_vsx_st</systemitem> for GCC.</para>
    <para>You should use the POWER7 and VSX loads and stores whenever you <emphasis>do not control</emphasis> buffers or their alignments, like a message in a buffer supplied by the user.</para>
    <para>The C/C++ code to perform a load using <systemitem>vec_xl</systemitem> and <systemitem>vec_vsx_ld</systemitem> should look similar to below. The function name has a <systemitem>u</systemitem> added to indicate unaligned.</para>
    <programlisting><indexterm><primary>VecLoad</primary></indexterm><indexterm><primary>vec_xl</primary></indexterm><indexterm><primary>vec_vsx_ld</primary></indexterm>template &lt;class T&gt;
uint32x4_p VecLoadu(const T* mem_addr, int offset)
{
#if defined(__xlc__) || defined(__xlC__)
    return (uint32x4_p)vec_xl(offset, mem_addr);
#else
    return (uint32x4_p)vec_vsx_ld(offset, mem_addr);
#endif
}</programlisting>
    <para>The C/C++ code to perform a store using <systemitem>vec_xst</systemitem> and <systemitem>vec_vsx_st</systemitem> should look similar to below.</para>
    <programlisting><indexterm><primary>VecStore</primary></indexterm><indexterm><primary>vec_xst</primary></indexterm><indexterm><primary>vec_vsx_st</primary></indexterm>template &lt;class T&gt;
void VecStoreu(const uint32x4_p val, T* mem_addr, int offset)
{
#if defined(__xlc__) || defined(__xlC__)
    vec_xst((uint8x16_p)val, offset, mem_addr);
#else
    vec_vsx_st((uint8x16_p)val, offset, mem_addr);
#endif
}</programlisting>
    <para>If your code will only be compiled with supported compilers, you may simplify it to use the <systemitem>vec_xl</systemitem> and <systemitem>vec_xst</systemitem> variants for both XLC and GCC.</para>
  </section>
  <section id="power8_vec_deref" xreflabel="Vector Dereferences">
    <title>Vector dereferences</title>
    <para>
      The <ulink url="https://openpowerfoundation.org/?resource_lib=64-bit-elf-v2-abi-specification-power-architecture">OpenPOWER ELF V2 ABI Specification</ulink>, version 1.4, incorrectly states that accessing vectors on Power should preferably be done with vector pointers and the dereference <systemitem>operator *</systemitem>. However, this is only permitted for aligned vector references.  Examples in Chapter 6 of the ABI document show use of casting operations that represent undefined behavior according to the C standard.  An errata document that corrects the ABI may be found <ulink url="https://openpowerfoundation.org/?resource_lib=openpower-elfv2-errata-elfv2-abi-version-1-4">at the OpenPOWER Foundation website</ulink>. Subsequent sections describe the proper way to use loads and stores of aligned and unaligned data.
    </para>
  </section>
</chapter>
